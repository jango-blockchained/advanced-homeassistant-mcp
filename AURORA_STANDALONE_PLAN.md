# Aurora Standalone AI Light Show System - Comprehensive Plan

## ðŸŽ¯ Project Overview

Create a **standalone Python/AI application** that performs intelligent sound-to-light synchronization with zero Home Assistant dependency (except optional initial device discovery). This will be a production-ready light show system with:

- âœ¨ Multiple intelligent light modes and effects
- ðŸŽµ Real-time sound-to-light synchronization
- ðŸ¤– AI-driven parameter optimization
- ðŸŽ¨ Professional light animation system
- ðŸ“± Web UI for control and visualization
- ðŸ”Œ Direct device protocol support (no HA relay needed)

---

## ðŸ“Š System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Aurora Standalone - AI Light Show System            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Layer 1: Audio Analysis & Intelligence             â”‚   â”‚
â”‚  â”‚ â”œâ”€ Real-time FFT analysis (numpy/scipy)           â”‚   â”‚
â”‚  â”‚ â”œâ”€ BPM detection & beat tracking                   â”‚   â”‚
â”‚  â”‚ â”œâ”€ Frequency band extraction (bass/mid/treble)    â”‚   â”‚
â”‚  â”‚ â”œâ”€ Mood/genre classification (ML)                 â”‚   â”‚
â”‚  â”‚ â”œâ”€ Spectral analysis for color mapping            â”‚   â”‚
â”‚  â”‚ â””â”€ Amplitude envelope tracking                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â†“                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Layer 2: Device Management & Discovery             â”‚   â”‚
â”‚  â”‚ â”œâ”€ Home Assistant optional integration             â”‚   â”‚
â”‚  â”‚ â”œâ”€ Direct Zigbee device support (ZHA/Z2M)        â”‚   â”‚
â”‚  â”‚ â”œâ”€ LIFX direct API (UDP/LIFX protocol)            â”‚   â”‚
â”‚  â”‚ â”œâ”€ Phillips Hue direct API (REST/CoAP)            â”‚   â”‚
â”‚  â”‚ â”œâ”€ Generic MQTT protocol support                  â”‚   â”‚
â”‚  â”‚ â”œâ”€ Device profiling & capability detection        â”‚   â”‚
â”‚  â”‚ â”œâ”€ Latency measurement & compensation             â”‚   â”‚
â”‚  â”‚ â””â”€ Device profile database (SQLite)               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â†“                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Layer 3: Rendering Engine                          â”‚   â”‚
â”‚  â”‚ â”œâ”€ Timeline pre-rendering                          â”‚   â”‚
â”‚  â”‚ â”œâ”€ Audio-to-light mapping algorithms               â”‚   â”‚
â”‚  â”‚ â”œâ”€ Device-specific effect generation               â”‚   â”‚
â”‚  â”‚ â”œâ”€ Synchronization calculation                     â”‚   â”‚
â”‚  â”‚ â”œâ”€ Color palette selection                         â”‚   â”‚
â”‚  â”‚ â””â”€ Timeline compression & optimization             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â†“                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Layer 4: Playback & Execution                      â”‚   â”‚
â”‚  â”‚ â”œâ”€ High-precision command timing                   â”‚   â”‚
â”‚  â”‚ â”œâ”€ Multi-device parallel execution                 â”‚   â”‚
â”‚  â”‚ â”œâ”€ Command batching & optimization                 â”‚   â”‚
â”‚  â”‚ â”œâ”€ Live mode (real-time mic input)                â”‚   â”‚
â”‚  â”‚ â”œâ”€ Pre-rendered mode (timeline playback)           â”‚   â”‚
â”‚  â”‚ â””â”€ Error recovery & retry logic                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â†“                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Layer 5: Intelligent Light Modes                   â”‚   â”‚
â”‚  â”‚ â”œâ”€ Rhythm Sync (beats â†’ brightness pulses)        â”‚   â”‚
â”‚  â”‚ â”œâ”€ Spectrum Analyzer (freq â†’ color gradient)       â”‚   â”‚
â”‚  â”‚ â”œâ”€ Mood-Based Colors (genre/energy â†’ palette)     â”‚   â”‚
â”‚  â”‚ â”œâ”€ Energy Reactive (amplitude â†’ brightness)        â”‚   â”‚
â”‚  â”‚ â”œâ”€ Gradient Flow (smooth color transitions)        â”‚   â”‚
â”‚  â”‚ â”œâ”€ Strobe Effects (tempo-locked)                   â”‚   â”‚
â”‚  â”‚ â”œâ”€ Wave Effects (directional patterns)             â”‚   â”‚
â”‚  â”‚ â””â”€ Custom Pattern Editor (UI-driven)               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â†“                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Layer 6: Web Interface & Control                   â”‚   â”‚
â”‚  â”‚ â”œâ”€ React/Vue frontend                              â”‚   â”‚
â”‚  â”‚ â”œâ”€ Real-time visualization                         â”‚   â”‚
â”‚  â”‚ â”œâ”€ Audio file management                           â”‚   â”‚
â”‚  â”‚ â”œâ”€ Timeline library                                â”‚   â”‚
â”‚  â”‚ â”œâ”€ Device control panel                            â”‚   â”‚
â”‚  â”‚ â”œâ”€ Effect customization                            â”‚   â”‚
â”‚  â”‚ â””â”€ Live preview/demo modes                         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Supporting Services                                â”‚   â”‚
â”‚  â”‚ â”œâ”€ FastAPI REST backend                            â”‚   â”‚
â”‚  â”‚ â”œâ”€ WebSocket for real-time updates                 â”‚   â”‚
â”‚  â”‚ â”œâ”€ SQLite database (profiles, timelines, settings) â”‚   â”‚
â”‚  â”‚ â””â”€ File storage (audio files, rendered timelines)  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ—ï¸ Tech Stack Recommendations

### Core Audio Processing
| Component | Technology | Reason |
|-----------|-----------|--------|
| **FFT Analysis** | `librosa` / `scipy.signal` | Industry standard, accurate, fast |
| **Real-time Audio** | `sounddevice` + `numpy` | Low-latency capture |
| **BPM Detection** | `librosa` (tempogram) | Most accurate beat tracking |
| **Beat Detection** | Custom onset detection | More reliable than libs |
| **Audio Formats** | `pydub` / `librosa` | MP3, OGG, FLAC, WAV support |

### Device Communication
| Protocol | Speed | Use Case | Implementation |
|----------|-------|----------|-----------------|
| **LIFX UDP** | ~5-10ms | LIFX-only setups | `ailifx` or custom |
| **Zigbee (direct)** | ~50-100ms | Home Assistant devices | `zigpy` / `z2m` API |
| **Phillips Hue CoAP** | ~30-50ms | Hue bridges | Direct bridge API |
| **MQTT** | ~100-200ms | Tasmota/ESPHome | `paho-mqtt` |
| **Home Assistant REST** | ~100-500ms | HA fallback | `httpx` async |
| **WebSocket** | ~50-100ms | Real-time sync | `websockets` |

**Recommendation**: Support LIFX (fastest) + Zigbee direct (most common) + MQTT (most flexible) as priority 1.

### Rendering & Effects
| Component | Technology | Reason |
|-----------|-----------|--------|
| **Color Science** | `colorspacious` / `colormath` | Accurate RGB/HSV/LAB conversion |
| **Pattern Generation** | `numpy` | Fast mathematical effects |
| **Timing Precision** | `asyncio` + `time.monotonic()` | Microsecond accuracy |
| **Timeline Storage** | JSON + `msgpack` | Compact efficient format |

### AI & Machine Learning
| Task | Technology | Notes |
|------|-----------|-------|
| **Genre Classification** | `librosa` + pre-trained models | Music mood/genre |
| **Color Palettes** | Pre-trained color schemes | Genre-based palettes |
| **Pattern Learning** | Rules-based (Phase 1) | ML later (Phase 2) |
| **Parameter Optimization** | Genetic algorithms / PSO | Fine-tune light mappings |

### Backend Framework
| Component | Technology | Reason |
|-----------|-----------|--------|
| **Web Framework** | `FastAPI` | Async, modern, WebSocket native |
| **Database** | `SQLite` + `SQLAlchemy` | Lightweight, portable |
| **Async Runtime** | `asyncio` (built-in) | Native Python, battle-tested |
| **CORS/Security** | FastAPI middleware | Built-in solutions |

### Frontend UI
| Component | Technology | Reason |
|-----------|-----------|--------|
| **Framework** | React or Vue | Reuse Aurora-UI experience |
| **Real-time** | WebSocket + React hooks | Live sync, low latency |
| **Visualization** | `Wavesurfer.js` / `Canvas API` | Waveform + spectrum display |
| **Styling** | Tailwind CSS | Consistent, fast |

---

## âš¡ Communication Protocol Strategy

### Why Not Home Assistant for Standalone?
- HA adds 100-500ms latency (REST API overhead)
- HA rate-limits commands (~60/sec)
- Network dependency (WiFi reliability)
- HA must be running (not always available)

### Best Approach for Real-Time Sync
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Aurora     â”‚        â”‚   Network   â”‚       â”‚ Smart Lights â”‚
â”‚  Standalone  â”‚â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ (direct or  â”‚â”€â”€â”€â”€â”€â”€â–¶â”‚ (multiple    â”‚
â”‚              â”‚        â”‚  local LAN) â”‚       â”‚  protocols)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†‘                                              â†‘
   Renders                                    Fast Response
   Timeline                                   5-100ms
   Calculates
   Timing
```

### Protocol Priority & Latency
1. **LIFX UDP** - 5-10ms (fastest, local only)
2. **Zigbee Direct** (via Z2M) - 50-100ms
3. **CoAP** (Hue bridge) - 30-50ms
4. **WebSocket** - 50-100ms
5. **MQTT** - 100-200ms
6. **REST/HTTP** - 100-500ms (use only as fallback)

### Recommended Setup
- **Priority 1**: Direct device APIs (LIFX, Hue bridge)
- **Priority 2**: Zigbee2MQTT for generic Zigbee devices
- **Priority 3**: MQTT for ESPHome/Tasmota devices
- **Optional**: Home Assistant for discovery only (device list scan)

---

## ðŸ“ Project Structure

```
aurora/
â”œâ”€â”€ README.md                          # Project overview
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ setup.py                          # Package setup
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ default_config.yaml           # Default settings
â”‚   â”œâ”€â”€ device_profiles.json          # Device capabilities
â”‚   â””â”€â”€ color_schemes.json            # Mood-based palettes
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ aurora/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py                   # Entry point
â”‚   â”‚   â”œâ”€â”€ config.py                 # Configuration management
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ audio/
â”‚   â”‚   â”‚   â”œâ”€â”€ analyzer.py           # FFT, BPM, beat detection
â”‚   â”‚   â”‚   â”œâ”€â”€ capture.py            # Live mic & file input
â”‚   â”‚   â”‚   â”œâ”€â”€ features.py           # Audio feature extraction
â”‚   â”‚   â”‚   â””â”€â”€ utils.py              # Audio utilities
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ devices/
â”‚   â”‚   â”‚   â”œâ”€â”€ manager.py            # Device manager (unified API)
â”‚   â”‚   â”‚   â”œâ”€â”€ scanner.py            # Device discovery
â”‚   â”‚   â”‚   â”œâ”€â”€ profiler.py           # Latency testing
â”‚   â”‚   â”‚   â”œâ”€â”€ protocols/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ lifx.py           # LIFX UDP protocol
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ zigbee.py         # Zigbee direct support
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ hue.py            # Philips Hue REST/CoAP
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ mqtt.py           # MQTT protocol
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ homeassistant.py  # HA REST API
â”‚   â”‚   â”‚   â””â”€â”€ models.py             # Device models
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ rendering/
â”‚   â”‚   â”‚   â”œâ”€â”€ timeline.py           # Timeline generation
â”‚   â”‚   â”‚   â”œâ”€â”€ mapper.py             # Audio-to-light mapping
â”‚   â”‚   â”‚   â”œâ”€â”€ synchronizer.py       # Latency compensation
â”‚   â”‚   â”‚   â”œâ”€â”€ effects/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ rhythm_sync.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ spectrum.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ mood_colors.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ energy_reactive.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ gradients.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ strobe.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ waves.py
â”‚   â”‚   â”‚   â””â”€â”€ color_lib.py          # Color science
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ execution/
â”‚   â”‚   â”‚   â”œâ”€â”€ executor.py           # Timeline playback
â”‚   â”‚   â”‚   â”œâ”€â”€ command_queue.py      # Command scheduling
â”‚   â”‚   â”‚   â”œâ”€â”€ timing.py             # Precise timing control
â”‚   â”‚   â”‚   â””â”€â”€ player.py             # Audio playback sync
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ai/
â”‚   â”‚   â”‚   â”œâ”€â”€ mood_classifier.py    # Genre/mood detection
â”‚   â”‚   â”‚   â”œâ”€â”€ optimizer.py          # Parameter optimization
â”‚   â”‚   â”‚   â””â”€â”€ pattern_learner.py    # Effect learning
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”‚   â”œâ”€â”€ models.py             # SQLAlchemy models
â”‚   â”‚   â”‚   â”œâ”€â”€ repository.py         # Data access layer
â”‚   â”‚   â”‚   â””â”€â”€ migrations/
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ server.py             # FastAPI app
â”‚   â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ audio.py          # Audio endpoints
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ devices.py        # Device endpoints
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ playback.py       # Playback control
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ effects.py        # Effect management
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ timelines.py      # Timeline library
â”‚   â”‚   â”‚   â””â”€â”€ websocket.py          # WebSocket handlers
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”‚   â”œâ”€â”€ logger.py
â”‚   â”‚   â”‚   â”œâ”€â”€ timing.py
â”‚   â”‚   â”‚   â”œâ”€â”€ validators.py
â”‚   â”‚   â”‚   â””â”€â”€ converters.py
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ constants.py
â”‚   â”‚
â”‚   â””â”€â”€ ui/                           # React/Vue frontend
â”‚       â”œâ”€â”€ public/
â”‚       â”œâ”€â”€ src/
â”‚       â”‚   â”œâ”€â”€ components/
â”‚       â”‚   â”œâ”€â”€ pages/
â”‚       â”‚   â”œâ”€â”€ hooks/
â”‚       â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ package.json
â”‚       â””â”€â”€ vite.config.ts
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_audio.py
â”‚   â”œâ”€â”€ test_devices.py
â”‚   â”œâ”€â”€ test_rendering.py
â”‚   â””â”€â”€ test_effects.py
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ INSTALLATION.md
â”‚   â”œâ”€â”€ CONFIGURATION.md
â”‚   â”œâ”€â”€ PROTOCOLS.md
â”‚   â”œâ”€â”€ EFFECTS.md
â”‚   â””â”€â”€ API.md
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ basic_sync.py
â”‚   â”œâ”€â”€ device_discovery.py
â”‚   â””â”€â”€ custom_effect.py
â””â”€â”€ docker/
    â”œâ”€â”€ Dockerfile
    â””â”€â”€ docker-compose.yml
```

---

## ðŸŽ¨ Light Modes & Effects (Priority 1)

### Must-Have Modes
1. **Rhythm Sync** - Beats â†’ Brightness pulses (universal effect)
2. **Spectrum Analyzer** - Frequency bands â†’ Color gradients
3. **Mood-Based Colors** - Genre/energy â†’ Dynamic palette
4. **Energy Reactive** - Amplitude envelope â†’ Brightness/saturation
5. **Gradient Flow** - Smooth color transitions following music
6. **Beat-Locked Strobe** - Synchronized strobe patterns
7. **Wave Effects** - Spatial patterns across grouped lights

### Advanced Modes (Phase 2)
- Harmonic color mapping
- Synchronized movement/directions
- Multi-zone coordination
- Custom pattern editor
- AI-suggested effects

---

## ðŸš€ Implementation Roadmap

### Phase 1: Foundation (Weeks 1-2)
- [x] Create standalone repo structure
- [ ] Core audio analysis (FFT, BPM, beat detection)
- [ ] Device manager with LIFX support
- [ ] Basic timeline rendering
- [ ] FastAPI server skeleton

**Deliverable**: CLI tool that renders audio â†’ timeline

### Phase 2: Device Support (Week 3)
- [ ] Zigbee direct protocol support
- [ ] Phillips Hue bridge integration
- [ ] MQTT device support
- [ ] Device profiling & latency measurement
- [ ] Timeline executor with precise timing

**Deliverable**: Command-line playback of light shows

### Phase 3: Web UI (Week 4)
- [ ] React/Vue frontend setup
- [ ] Audio file upload & visualization
- [ ] Device discovery & management UI
- [ ] Playback controls
- [ ] Effect library browser

**Deliverable**: Full web UI for non-technical users

### Phase 4: Advanced Features (Week 5+)
- [ ] AI mood/genre detection
- [ ] Real-time microphone input
- [ ] Live mode (sub-50ms latency)
- [ ] Custom pattern editor
- [ ] Timeline library & templates
- [ ] Performance optimization

**Deliverable**: Production-ready AI light show system

---

## ðŸ”Œ Device Discovery Strategy

### Initial Discovery (One-time setup)
```
User Options:
1. Home Assistant API (auto-discover all lights)
2. Manual device entry (IP addresses, IDs)
3. Network scan (LIFX/Hue broadcast discovery)
4. Zigbee2MQTT API (if available)
```

### Device Profile Storage
```json
{
  "device_id": "light.bedroom_bulb",
  "name": "Bedroom Bulb",
  "type": "LIFX",
  "ip_address": "192.168.1.100",
  "capabilities": ["color", "brightness", "transition"],
  "latency_ms": 15,
  "transition_time_min": 100,
  "transition_time_max": 2000,
  "color_space": "RGB",
  "last_profile_date": "2024-11-10"
}
```

---

## âš™ï¸ Technical Requirements

### Python Dependencies
```
numpy>=1.24.0              # Numerical computing
scipy>=1.10.0              # Signal processing (FFT)
librosa>=0.10.0            # Audio feature extraction
sounddevice>=0.4.5         # Real-time audio I/O
pydub>=0.25.1              # Audio format conversion
fastapi>=0.104.0           # Web framework
uvicorn>=0.24.0            # ASGI server
sqlalchemy>=2.0.0          # ORM
pydantic>=2.0.0            # Data validation
websockets>=12.0           # WebSocket support
httpx>=0.25.0              # Async HTTP
paho-mqtt>=1.6.1           # MQTT client
aiohttp>=3.9.0             # Async HTTP for LIFX
colorspacious>=1.1.1       # Color science
```

### Performance Targets
- **Timeline pre-rendering**: 2-10x real-time (1min audio in 6-60s)
- **Command latency**: < 100ms total (device send + response)
- **UI responsiveness**: < 200ms reaction time
- **Live mode**: < 50ms audio capture to light response

### Storage Requirements
- Device profiles: ~5KB per device (1000 devices = 5MB)
- Timeline database: ~1MB per 1hr of music
- Audio cache: As-needed per file

---

## ðŸ”’ Security & Deployment

### Deployment Options
1. **Docker Compose** - Full stack (Python backend + React UI)
2. **Systemd Service** - Linux native
3. **PyInstaller Bundle** - Standalone executable
4. **Cloud Ready** - AWS/DigitalOcean compatible

### Security Considerations
- Local network only (no internet required)
- Optional authentication for UI
- Token-based device access
- Encrypted credential storage
- No third-party tracking

---

## ðŸ“ˆ Success Metrics

âœ… Phase 1 Complete:
- Renders audio to pre-timed light commands
- Supports â‰¥2 device types (LIFX + Zigbee)
- Web UI operational
- <100ms command latency achieved

âœ… Phase 2 Complete:
- All 7 light modes working
- Real-time visualization
- Device discovery optimized
- Live mode achieves <50ms latency

âœ… Phase 3 Complete:
- AI mood detection integrated
- Performance benchmarked (1000+ devices)
- User testing completed
- Documentation complete

---

## ðŸŽ¯ Next Steps

1. **Create aurora repo** at `~/Git/aurora`
2. **Extract core modules** from homeassistant-mcp
3. **Refactor for standalone** (remove HA dependencies)
4. **Implement Phase 1** systems
5. **Research & integrate** fastest device protocols
6. **Optimize timing** for sub-100ms latency

---

## ðŸ“š References & Research

### Web Search Results Summary
- **WebSocket vs REST**: WebSocket 10-100x lower latency for real-time apps
- **Beat Detection**: Onset-based algorithms most reliable (librosa recommended)
- **Light Protocols**: LIFX UDP fastest (5-10ms), Zigbee 50-100ms, MQTT 100-200ms
- **Python Audio**: librosa (FFT), sounddevice (real-time capture) industry standard

### Key Insights
âœ¨ **Direct device protocols > Home Assistant relay** for performance
âœ¨ **Pre-rendering > live processing** for perfect sync
âœ¨ **WebSocket > REST** for real-time UI updates
âœ¨ **Async Python** (asyncio) critical for multi-device coordination
âœ¨ **Device profiling** essential for latency compensation

---

## âœ… Approval Checklist

- [ ] Review architecture & tech stack
- [ ] Approve timeline (5-6 weeks estimated)
- [ ] Confirm device protocol priorities
- [ ] Discuss deployment preferences
- [ ] Budget for research time (~20% of schedule)

